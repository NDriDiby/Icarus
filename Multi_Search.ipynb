{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to go\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docx\n",
    "print(\"ready to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-search (Keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "f\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "doc = ['A','B','c','D','f','g']\n",
    "for w in range(0,len(doc)):\n",
    "    words=doc[w].lower()\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords found in the document: {'a', 'd', 'h', 'b', 'c'}\n",
      "a : 6\n",
      "b : 4\n",
      "c : 2\n",
      "d : 2\n",
      "h : 2\n"
     ]
    }
   ],
   "source": [
    "doc = ['A','B','c','D','f','g','H','a','a','b','G','g','A','B','c','D','f','g','H','a','a','b','G','g'] #Actual document.\n",
    "kw=['a','b','d','c','h'] #List of keywords we want to find in the document.\n",
    "key=[] #List of the keyword found in the document.\n",
    "freq=[] #list of the number of keyword found in the document.\n",
    "for low in range(0,len(doc)):\n",
    "    words=doc[low].lower()#lowerCase's version of the document.\n",
    "    for i in range(0,len(kw)):\n",
    "        if kw[i] in words:\n",
    "            key.append(kw[i])\n",
    "            #result = key.count(kw[i])\n",
    "            #print(kw[i],\":\",result)\n",
    "\n",
    "unik = set(key)\n",
    "print(\"Keywords found in the document:\", unik)\n",
    "for i in range(0,len(unik)):\n",
    "    freq.append(key.count(key[i]))\n",
    "    print(key[i],\":\",key.count(key[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd', 'h'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print list = position of keyword in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd', 'h'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uniquekey = np.unique(key)\n",
    "unik = set(key)\n",
    "unik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(key.count('a'))\n",
    "print(key.count('c'))\n",
    "print(key.count('d'))\n",
    "print(key.count('f'))\n",
    "print(key.count('g'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : 6\n",
      "b : 4\n",
      "c : 2\n",
      "d : 2\n",
      "h : 2\n"
     ]
    }
   ],
   "source": [
    " freq= []\n",
    "for i in range(0,len(unik)):\n",
    "    #int= key.count(key[i])\n",
    "    freq.append(key.count(key[i]))\n",
    "    print(key[i],\":\",key.count(key[i]))\n",
    "    \n",
    "    \n",
    "#print(key.count('g'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 2, 2, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Frequency as a percentage(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWordFreq = len(key)/len(doc)\n",
    "keyWordFreq\n",
    "#Among all the keywords we were lookingup up, 72.72% appear to be in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame of keyword and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((key,freq), columns=[\"keyword\",\"freq\"]) #index=[\"2015\",\"2016\",'2017','2018','2019','2020','2021','2021'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c128d71b3023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw1</th>\n",
       "      <th>kw2</th>\n",
       "      <th>kw3</th>\n",
       "      <th>kw4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year_1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_4</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        kw1  kw2  kw3  kw4\n",
       "year_1    3    2    1    0\n",
       "year_2    5    6    2    9\n",
       "year_3    4    2    8    1\n",
       "year_4    2    9    2    9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'year_1': [3, 2, 1, 0], 'year_2': [5, 6, 2, 9],'year_3': [4, 2, 8, 1], 'year_4': [2, 9, 2, 9]}\n",
    "pd.DataFrame.from_dict(data, orient='index', columns=['kw1', 'kw2', 'kw3', 'kw4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golden Function: Multi-Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents=[] \n",
    "def doc(str):\n",
    "    docs=docx.Document(str)\n",
    "    for para in docs.paragraphs:\n",
    "        documents.append(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(\"/Users/pm3796gb/Downloads/Facebook .docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook on Tuesday\\xa0said\\xa0it will now let users see which outside websites are tracking their activity and prevent Facebook from using that data for ad targeting—a small, but potentially powerful change that could weaken Facebook’s ad tools while making Facebook ads less invasive for users.',\n",
       " '',\n",
       " 'The tool, called Off-Facebook Activity, shows users a summary of the information other apps and websites have sent Facebook and lets them clear it from their account.',\n",
       " 'Users can also prevent any future data from being used for ad targeting.\\xa0',\n",
       " 'It doesn’t prevent Facebook from collecting that data in the first place, but instead keeps it anonymized.',\n",
       " 'The new tool will be rolled out gradually over the coming months, starting with Ireland, South Korea and Spain.']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase version of the document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'on', 'Tuesday', 'said', 'it', 'will', 'now', 'let', 'users', 'see', 'which', 'outside', 'websites', 'are', 'tracking', 'their', 'activity', 'and', 'prevent', 'Facebook', 'from', 'using', 'that', 'data', 'for', 'ad', 'targeting—a', 'small,', 'but', 'potentially', 'powerful', 'change', 'that', 'could', 'weaken', 'Facebook’s', 'ad', 'tools', 'while', 'making', 'Facebook', 'ads', 'less', 'invasive', 'for', 'users.']\n",
      "[]\n",
      "['The', 'tool,', 'called', 'Off-Facebook', 'Activity,', 'shows', 'users', 'a', 'summary', 'of', 'the', 'information', 'other', 'apps', 'and', 'websites', 'have', 'sent', 'Facebook', 'and', 'lets', 'them', 'clear', 'it', 'from', 'their', 'account.']\n",
      "['Users', 'can', 'also', 'prevent', 'any', 'future', 'data', 'from', 'being', 'used', 'for', 'ad', 'targeting.']\n",
      "['It', 'doesn’t', 'prevent', 'Facebook', 'from', 'collecting', 'that', 'data', 'in', 'the', 'first', 'place,', 'but', 'instead', 'keeps', 'it', 'anonymized.']\n",
      "['The', 'new', 'tool', 'will', 'be', 'rolled', 'out', 'gradually', 'over', 'the', 'coming', 'months,', 'starting', 'with', 'Ireland,', 'South', 'Korea', 'and', 'Spain.']\n"
     ]
    }
   ],
   "source": [
    "roc=[]\n",
    "for i in range(0,len(documents)):\n",
    "    #print(documents[i].lower())\n",
    "    roc.append(documents[i].split())\n",
    "    print(documents[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Facebook',\n",
       "  'on',\n",
       "  'Tuesday',\n",
       "  'said',\n",
       "  'it',\n",
       "  'will',\n",
       "  'now',\n",
       "  'let',\n",
       "  'users',\n",
       "  'see',\n",
       "  'which',\n",
       "  'outside',\n",
       "  'websites',\n",
       "  'are',\n",
       "  'tracking',\n",
       "  'their',\n",
       "  'activity',\n",
       "  'and',\n",
       "  'prevent',\n",
       "  'Facebook',\n",
       "  'from',\n",
       "  'using',\n",
       "  'that',\n",
       "  'data',\n",
       "  'for',\n",
       "  'ad',\n",
       "  'targeting—a',\n",
       "  'small,',\n",
       "  'but',\n",
       "  'potentially',\n",
       "  'powerful',\n",
       "  'change',\n",
       "  'that',\n",
       "  'could',\n",
       "  'weaken',\n",
       "  'Facebook’s',\n",
       "  'ad',\n",
       "  'tools',\n",
       "  'while',\n",
       "  'making',\n",
       "  'Facebook',\n",
       "  'ads',\n",
       "  'less',\n",
       "  'invasive',\n",
       "  'for',\n",
       "  'users.'],\n",
       " [],\n",
       " ['The',\n",
       "  'tool,',\n",
       "  'called',\n",
       "  'Off-Facebook',\n",
       "  'Activity,',\n",
       "  'shows',\n",
       "  'users',\n",
       "  'a',\n",
       "  'summary',\n",
       "  'of',\n",
       "  'the',\n",
       "  'information',\n",
       "  'other',\n",
       "  'apps',\n",
       "  'and',\n",
       "  'websites',\n",
       "  'have',\n",
       "  'sent',\n",
       "  'Facebook',\n",
       "  'and',\n",
       "  'lets',\n",
       "  'them',\n",
       "  'clear',\n",
       "  'it',\n",
       "  'from',\n",
       "  'their',\n",
       "  'account.'],\n",
       " ['Users',\n",
       "  'can',\n",
       "  'also',\n",
       "  'prevent',\n",
       "  'any',\n",
       "  'future',\n",
       "  'data',\n",
       "  'from',\n",
       "  'being',\n",
       "  'used',\n",
       "  'for',\n",
       "  'ad',\n",
       "  'targeting.'],\n",
       " ['It',\n",
       "  'doesn’t',\n",
       "  'prevent',\n",
       "  'Facebook',\n",
       "  'from',\n",
       "  'collecting',\n",
       "  'that',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'place,',\n",
       "  'but',\n",
       "  'instead',\n",
       "  'keeps',\n",
       "  'it',\n",
       "  'anonymized.'],\n",
       " ['The',\n",
       "  'new',\n",
       "  'tool',\n",
       "  'will',\n",
       "  'be',\n",
       "  'rolled',\n",
       "  'out',\n",
       "  'gradually',\n",
       "  'over',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'months,',\n",
       "  'starting',\n",
       "  'with',\n",
       "  'Ireland,',\n",
       "  'South',\n",
       "  'Korea',\n",
       "  'and',\n",
       "  'Spain.']]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook\n",
      "on\n",
      "tuesday\n",
      "said\n",
      "it\n",
      "will\n",
      "now\n",
      "let\n",
      "users\n",
      "see\n",
      "which\n",
      "outside\n",
      "websites\n",
      "are\n",
      "tracking\n",
      "their\n",
      "activity\n",
      "and\n",
      "prevent\n",
      "facebook\n",
      "from\n",
      "using\n",
      "that\n",
      "data\n",
      "for\n",
      "ad\n",
      "targeting—a\n",
      "small,\n",
      "but\n",
      "potentially\n",
      "powerful\n",
      "change\n",
      "that\n",
      "could\n",
      "weaken\n",
      "facebook’s\n",
      "ad\n",
      "tools\n",
      "while\n",
      "making\n",
      "facebook\n",
      "ads\n",
      "less\n",
      "invasive\n",
      "for\n",
      "users.\n",
      "the\n",
      "tool,\n",
      "called\n",
      "off-facebook\n",
      "activity,\n",
      "shows\n",
      "users\n",
      "a\n",
      "summary\n",
      "of\n",
      "the\n",
      "information\n",
      "other\n",
      "apps\n",
      "and\n",
      "websites\n",
      "have\n",
      "sent\n",
      "facebook\n",
      "and\n",
      "lets\n",
      "them\n",
      "clear\n",
      "it\n",
      "from\n",
      "their\n",
      "account.\n",
      "users\n",
      "can\n",
      "also\n",
      "prevent\n",
      "any\n",
      "future\n",
      "data\n",
      "from\n",
      "being\n",
      "used\n",
      "for\n",
      "ad\n",
      "targeting.\n",
      "it\n",
      "doesn’t\n",
      "prevent\n",
      "facebook\n",
      "from\n",
      "collecting\n",
      "that\n",
      "data\n",
      "in\n",
      "the\n",
      "first\n",
      "place,\n",
      "but\n",
      "instead\n",
      "keeps\n",
      "it\n",
      "anonymized.\n",
      "the\n",
      "new\n",
      "tool\n",
      "will\n",
      "be\n",
      "rolled\n",
      "out\n",
      "gradually\n",
      "over\n",
      "the\n",
      "coming\n",
      "months,\n",
      "starting\n",
      "with\n",
      "ireland,\n",
      "south\n",
      "korea\n",
      "and\n",
      "spain.\n"
     ]
    }
   ],
   "source": [
    "roc3=[]\n",
    "for low in range(0,len(roc)):\n",
    "    roc2 = roc[low]\n",
    "    for lower in range(0,len(roc2)):\n",
    "        print(roc2[lower].lower())\n",
    "        roc3.append(roc2[lower].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"south\" in roc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : 1\n",
      "b : 1\n",
      "a : 2\n",
      "a : 3\n",
      "b : 2\n"
     ]
    }
   ],
   "source": [
    "docu=['A','B','C','a','a','B','c','c']\n",
    "keyword = ['a','b']\n",
    "find=[]\n",
    "freq=[]\n",
    "for i in range (0,len(docu)):\n",
    "    docuLow = docu[i].lower()\n",
    "    #print(docuLow)\n",
    "    for k in range(0,len(keyword)):\n",
    "        if keyword[k] in docuLow:\n",
    "            find.append(keyword[k])\n",
    "            print(keyword[k],\":\",find.count(keyword[k]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the doc\n",
    "d=[]\n",
    "def splitdoc(str):\n",
    "    docs=docx.Document(str)\n",
    "    for para in docs.paragraphs:\n",
    "        d.append(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdoc(\"/Users/pm3796gb/Downloads/Facebook .docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the document\n",
    "d2=[]\n",
    "for i in range(0,len(d)):\n",
    "    print(d[i].split())\n",
    "    d2.append(d[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(d2)):\n",
    "    d3=d2[i]\n",
    "    for x in range(0,len(d3)):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(str,word):\n",
    "    count=0\n",
    "    d=[]\n",
    "    doc=docx.Document(str)\n",
    "    for p in doc.paragraphs:\n",
    "        d.append(p.text.split())\n",
    "        for i in range(0,len(d)):\n",
    "            find=d[i]\n",
    "        for z in range(0,len(find)):\n",
    "            get=find[z]\n",
    "            #word=word.strip(\"!@#$%^&*()_+-'\")\n",
    "            if(word==get):\n",
    "                count+=1\n",
    "                print(word,\":\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"/Users/pm3796gb/Downloads/Facebook .docx\",\"starting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword search final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "finding=[]\n",
    "nofinding=[]\n",
    "frequency=[]\n",
    "words=[]\n",
    "paragraphs=[]\n",
    "docs\n",
    "docx\n",
    "def keyword(str,list):\n",
    "    docs=docx.Document(str)\n",
    "    for para in docs.paragraphs:\n",
    "        paragraphs.append(para.text.split())#parse the document\n",
    "        for p in range(0,len(paragraphs)):\n",
    "            onepara = paragraphs[p] #paragraph per para\n",
    "        for each in range(0,len(onepara)):\n",
    "            word = onepara[each].lower()\n",
    "            words.append(word)\n",
    "            for k in range(0,len(list)):\n",
    "                if (list[k]==word):\n",
    "                    finding.append(list[k])\n",
    "                #else:\n",
    "                   # nofinding.append(list[k])\n",
    "                    #count+=1\n",
    "                    #print(list[k],\":\",finding.count(list[k]))\n",
    "                    \n",
    "   # notfound=set(nofinding)                \n",
    "    unique=set(finding)\n",
    "    print(\"Keyword found in the document:\", unique)\n",
    "   # print(\"Keyword not found in the document:\", notfound)\n",
    "    print()\n",
    "    for i in range(0,len(unique)):\n",
    "        frequency.append(finding.count(list[i]))\n",
    "        print(list[i],\":\",finding.count(list[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword found in the document: {'users', 'websites', 'facebook'}\n",
      "\n",
      "facebook : 5\n",
      "users : 3\n",
      "websites : 2\n"
     ]
    }
   ],
   "source": [
    "#Enter the keywords in the sequence as they are appeard in the document. \n",
    "keyword(\"/Users/pm3796gb/Downloads/Facebook .docx\",['facebook','users','websites'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position of keywords in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facebook',\n",
       " 'users',\n",
       " 'websites',\n",
       " 'facebook',\n",
       " 'facebook',\n",
       " 'users',\n",
       " 'websites',\n",
       " 'facebook',\n",
       " 'users',\n",
       " 'facebook']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The sequence at which the words appeared into the document.\n",
    "finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of key words\n",
    "frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the document:  122\n",
      "Number of the paragraphs in the document:  6\n"
     ]
    }
   ],
   "source": [
    "print('Number of words in the document: ', len(words))\n",
    "print('Number of the paragraphs in the document: ', len(paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of word per paragraphs:  20\n"
     ]
    }
   ],
   "source": [
    "#Average words per paragraphs\n",
    "meanword= len(words)/len(paragraphs)\n",
    "print('Average number of word per paragraphs: ', round(meanword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative frequency of keywords:  0.49180327868852464\n"
     ]
    }
   ],
   "source": [
    "print (\"Relative frequency of keywords: \",len(finding)/meanword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the document in lower character\n",
    "docs=[]\n",
    "def loadDoc(str):\n",
    "    d=[]\n",
    "    doc=docx.Document(str)\n",
    "    for p in doc.paragraphs:\n",
    "        d.append(p.text)\n",
    "    for line in range(0,len(d)):\n",
    "        docs.append(d[line].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDoc(\"/Users/pm3796gb/Downloads/Facebook .docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "freqSentences=[]\n",
    "def keysentence(docs,list):\n",
    "        #count=0\n",
    "        for z in range(0,len(docs)):\n",
    "            #do=docs[z]\n",
    "            for i in range(0,len(list)):\n",
    "                if(list[i] in docs[z]):\n",
    "                    #count+=1\n",
    "                    sentences.append(list[i])\n",
    "                    freqSentences.append(sentences.count(sentences[i]))\n",
    "                    #print(list[i],':',sentences.count(sentences[i]))\n",
    "\n",
    "                    #result=(\"The sentence '{}' has appeared {} times in the document\")\n",
    "                    #print(result.format(str,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keysentence(docs,['facebook on tuesday','south korea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facebook on tuesday', 'south korea']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "senfinding=[]\n",
    "senfrequency=[]\n",
    "senwords=[]\n",
    "senparagraphs=[]\n",
    "def keysentence(str,list):\n",
    "    #count=0\n",
    "    #document=[]\n",
    "    docs=docx.Document(str)\n",
    "    for para in docs.paragraphs:\n",
    "        senparagraphs.append(para.text)#parse the document\n",
    "    for each in range(0,len(senparagraphs)):\n",
    "        senword = senparagraphs[each].lower()\n",
    "        senwords.append(senword)\n",
    "        for k in range(0,len(list)):\n",
    "             if (list[k] in senword):\n",
    "                     senfinding.append(list[k])\n",
    "        #else:\n",
    "                               \n",
    "                    #count+=1\n",
    "                    #print(list[k],\":\",finding.count(list[k]))\n",
    "                    \n",
    "    senunique=set(senfinding)\n",
    "    print(\"Keyword found in the document:\", senunique)\n",
    "    print()\n",
    "    for i in range(0,len(senunique)):\n",
    "        senfrequency.append(senfinding.count(list[i]))\n",
    "        print(list[i],\":\",senfinding.count(list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keysentence(\"/Users/pm3796gb/Downloads/Facebook .docx\",['facebook on','users','outside websites','south korea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senparagraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senfinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try keysentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword found in the document: {'union power', 'american automakers'}\n",
      "\n",
      "union power : 2\n",
      "american automakers : 2\n"
     ]
    }
   ],
   "source": [
    "keysentence(\"/Users/pm3796gb/Downloads/Automaker.docx\",['union power','american automakers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senfrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['american automakers', 'union power', 'union power', 'american automakers']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senfinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
